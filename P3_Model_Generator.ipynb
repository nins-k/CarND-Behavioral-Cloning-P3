{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for the training data\n",
    "\n",
    "base_dir = 'C:\\\\Users\\\\nins_\\\\Desktop\\\\Data3\\\\'\n",
    "csv_file_name = 'driving_log.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Convolution2D, MaxPooling2D, Activation, Cropping2D, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv and images into training and label numpy arrays\n",
    "df = pd.read_csv(base_dir+csv_file_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "data_train, data_valid = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator for supplying data to the model in batches\n",
    "\n",
    "def data_generator(data, batch_size):\n",
    "    \n",
    "    data = np.array(data)\n",
    "    total_samples = len(data)\n",
    "    \n",
    "    while(True):\n",
    "        \n",
    "        # Shuffle the data before each epoch\n",
    "        shuffle(data)\n",
    "        \n",
    "        # Obtain samples equal to batch size and process the images\n",
    "        for offset in range(0, total_samples, batch_size):\n",
    "            batch = data[offset:batch_size+offset]\n",
    "            \n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "            \n",
    "            # Load images and labels equal to the batch size only\n",
    "            for row in batch:\n",
    "                img_C = cv2.cvtColor(cv2.imread(row[0]), cv2.COLOR_BGR2RGB)\n",
    "                label_C = float(row[3])\n",
    "                \n",
    "                img_L = cv2.cvtColor(cv2.imread(row[1]), cv2.COLOR_BGR2RGB)\n",
    "                op = 0.7 if label_C < 0 else 1.3\n",
    "                label_L = op * label_C\n",
    "                \n",
    "                img_R = cv2.cvtColor(cv2.imread(row[2]), cv2.COLOR_BGR2RGB)\n",
    "                op = 1.3 if label_C < 0 else 0.7\n",
    "                label_R = op * label_C\n",
    "                \n",
    "                # Append to the batch data\n",
    "                batch_images.append(img_C)\n",
    "                batch_images.append(img_L)\n",
    "                batch_images.append(img_R)\n",
    "                \n",
    "                batch_labels.append(label_C)\n",
    "                batch_labels.append(label_L)\n",
    "                batch_labels.append(label_R)\n",
    "                \n",
    "                # Flip the image\n",
    "                flip_img_C = cv2.flip(img_C, 1)\n",
    "                flip_label_C = label_C * (-1)\n",
    "                \n",
    "                flip_img_L = cv2.flip(img_L, 1)\n",
    "                flip_label_L = label_L * (-1)\n",
    "                \n",
    "                flip_img_R = cv2.flip(img_R, 1)\n",
    "                flip_label_R = label_R * (-1)\n",
    "                \n",
    "                # Append the augmented data to the batch data\n",
    "                batch_images.append(flip_img_C)\n",
    "                batch_images.append(flip_img_L)\n",
    "                batch_images.append(flip_img_R)\n",
    "                \n",
    "                batch_labels.append(flip_label_C)\n",
    "                batch_labels.append(flip_label_L)\n",
    "                batch_labels.append(flip_label_R)\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            X = np.array(batch_images)\n",
    "            y = np.array(batch_labels)\n",
    "\n",
    "            yield shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generators for training and validation\n",
    "\n",
    "train_generator = data_generator(data_train, batch_size=16)\n",
    "valid_generator = data_generator(data_valid, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "cropping2d_1 (Cropping2D)        (None, 90, 320, 3)    0           cropping2d_input_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 86, 316, 8)    608         cropping2d_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 43, 158, 8)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 43, 158, 8)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 41, 156, 6)    438         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 20, 78, 6)     0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 20, 78, 6)     0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 20, 78, 6)     330         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 10, 39, 6)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 10, 39, 6)     0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 2340)          0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 300)           702300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 300)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 150)           45150       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 150)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 80)            12080       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 80)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             81          dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 760,987\n",
      "Trainable params: 760,987\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))\n",
    "\n",
    "model.add(Convolution2D(8, 5, 5, border_mode='valid', subsample=(1,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Activation(activation='relu'))\n",
    "\n",
    "model.add(Convolution2D(6, 3, 3, border_mode='valid', subsample=(1,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Activation(activation='relu'))\n",
    "\n",
    "model.add(Convolution2D(6, 3, 3, border_mode='same', subsample=(1,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Activation(activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2592/2679 [============================>.] - ETA: 1s - loss: 3090.8661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Programming_Tools\\Anaconda\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688/2679 [==============================] - 42s - loss: 2981.0326 - val_loss: 0.4925\n",
      "Epoch 2/40\n",
      "2688/2679 [==============================] - 26s - loss: 4.0678 - val_loss: 0.0481\n",
      "Epoch 3/40\n",
      "2688/2679 [==============================] - 25s - loss: 0.3301 - val_loss: 0.0422\n",
      "Epoch 4/40\n",
      "2688/2679 [==============================] - 26s - loss: 0.1176 - val_loss: 0.0199\n",
      "Epoch 5/40\n",
      "2688/2679 [==============================] - 26s - loss: 0.0747 - val_loss: 0.0307\n",
      "Epoch 6/40\n",
      "2730/2679 [==============================] - 27s - loss: 0.0474 - val_loss: 0.0165\n",
      "Epoch 7/40\n",
      "2688/2679 [==============================] - 26s - loss: 0.0449 - val_loss: 0.0213\n",
      "Epoch 8/40\n",
      "2688/2679 [==============================] - 27s - loss: 0.0278 - val_loss: 0.0298\n",
      "Epoch 9/40\n",
      "2688/2679 [==============================] - 25s - loss: 0.0291 - val_loss: 0.0255\n",
      "Epoch 10/40\n",
      "2688/2679 [==============================] - 25s - loss: 0.0305 - val_loss: 0.0371\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "model.fit_generator(train_generator, callbacks=[checkpoint, earlystop], samples_per_epoch=len(data_train), validation_data=valid_generator, nb_val_samples=len(data_valid), nb_epoch=40)\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
